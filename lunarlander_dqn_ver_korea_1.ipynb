{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lunarlander_dqn_ver_korea_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtu7E2suble7juFpKIOpMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matt700395/RL_1st/blob/master/lunarlander_dqn_ver_korea_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5bvffulKlj6",
        "outputId": "59a5f2fe-0f62-4ad5-f466-815b24a6d74d"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/uninstall.py\", line 86, in run\n",
            "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 658, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_uninstall.py\", line 380, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_uninstall.py\", line 423, in _allowed_to_proceed\n",
            "    return ask('Proceed (y/n)? ', ('y', 'n')) == 'y'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/misc.py\", line 203, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 213, in _main\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1366, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1127, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 130, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 616, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 566, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 104, in print_exception\n",
            "    type(value), value, tb, limit=limit).format(chain=chain):\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 508, in __init__\n",
            "    capture_locals=capture_locals)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 363, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 285, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 449, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 432, in detect_encoding\n",
            "    second = read_or_stop()\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdY0rI9LKoca"
      },
      "source": [
        "!pip install tensorflow==1.15 # 1.15 버전 Tensorflow 설치"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TyPF_wxFgjl",
        "outputId": "7effe75b-fa24-4d7e-a268-dae18feedee7"
      },
      "source": [
        "# see: colab.research.google.com/drive/1GLlB53gvZaUyqMYv8GmZQJmshRUzV_tg\n",
        "!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "\n",
        "!pip install stable-baselines==2.7.0\n",
        "\n",
        "# box2d fork until SWIG dependency is replaced\n",
        "!pip install box2d-py\n",
        "\n",
        "# pyglet later versions break gym apparently\n",
        "!pip install pyglet==1.3.2\n",
        "\n",
        "!pip install gym pyvirtualdisplay\n",
        "\n",
        "# Set up display; otherwise rendering will fail for\n",
        "# classic control type envs, apparently\n",
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "\n",
        "# See https://github.com/ipython/ipython/issues/10045#issuecomment-522697219\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Unable to locate package libcusparse8.0\n",
            "E: Couldn't find any package by glob 'libcusparse8.0'\n",
            "E: Couldn't find any package by regex 'libcusparse8.0'\n",
            "E: Unable to locate package libnvrtc8.0\n",
            "E: Couldn't find any package by glob 'libnvrtc8.0'\n",
            "E: Couldn't find any package by regex 'libnvrtc8.0'\n",
            "Collecting stable-baselines==2.7.0\n",
            "  Downloading stable_baselines-2.7.0-py3-none-any.whl (259 kB)\n",
            "\u001b[K     |████████████████████████████████| 259 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (3.2.2)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 66.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines==2.7.0) (2018.9)\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185295 sha256=1c370ef1b8bb0fc195de715a25e9d2936478535729905d1253e240d64f59ad0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py, stable-baselines\n",
            "Successfully installed mpi4py-3.1.3 stable-baselines-2.7.0\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 14.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Collecting pyglet==1.3.2\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires pyglet<=1.5.0,>=1.4.0, but you have pyglet 1.3.2 which is incompatible.\u001b[0m\n",
            "Successfully installed pyglet-1.3.2\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 15.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyglet, EasyProcess, pyvirtualdisplay\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.3.2\n",
            "    Uninstalling pyglet-1.3.2:\n",
            "      Successfully uninstalled pyglet-1.3.2\n",
            "Successfully installed EasyProcess-0.3 pyglet-1.5.0 pyvirtualdisplay-2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXKZVeUjFBqM"
      },
      "source": [
        "import sys\n",
        "import gym\n",
        "import pylab\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "\n",
        "# 카트폴 예제에서의 DQN 에이전트\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.render = False\n",
        "\n",
        "        # 상태와 행동의 크기 정의\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # DQN 하이퍼파라미터\n",
        "        self.discount_factor = 0.99\n",
        "        self.learning_rate = 0.001\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.999\n",
        "        self.epsilon_min = 0.01\n",
        "        #self.batch_size = 32\n",
        "        #self.train_start = 1000\n",
        "        self.batch_size = 5\n",
        "        self.train_start = 5\n",
        "\n",
        "        # 리플레이 메모리, 최대 크기 2000\n",
        "        #self.memory = deque(maxlen=20000)\n",
        "        self.memory = deque(maxlen=100)\n",
        "\n",
        "        # 모델과 타깃 모델 생성\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "\n",
        "        # 타깃 모델 초기화\n",
        "        self.update_target_model()\n",
        "\n",
        "\n",
        "    # 상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(30, input_dim=self.state_size, activation='relu',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.add(Dense(30, activation='relu',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.add(Dense(self.action_size, activation='linear',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.summary()\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    # 타깃 모델을 모델의 가중치로 업데이트\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    # 입실론 탐욕 정책으로 행동 선택\n",
        "    def get_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        else:\n",
        "            q_value = self.model.predict(state)\n",
        "            return np.argmax(q_value[0])\n",
        "\n",
        "    # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장\n",
        "    def append_sample(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "    def train_model(self):\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "        # 메모리에서 배치 크기만큼 무작위로 샘플 추출\n",
        "        mini_batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states = np.zeros((self.batch_size, self.state_size))\n",
        "        next_states = np.zeros((self.batch_size, self.state_size))\n",
        "        actions, rewards, dones = [], [], []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            states[i] = mini_batch[i][0]\n",
        "            actions.append(mini_batch[i][1])\n",
        "            rewards.append(mini_batch[i][2])\n",
        "            next_states[i] = mini_batch[i][3]\n",
        "            dones.append(mini_batch[i][4])\n",
        "\n",
        "        # 현재 상태에 대한 모델의 큐함수\n",
        "        # 다음 상태에 대한 타깃 모델의 큐함수\n",
        "        target = self.model.predict(states)\n",
        "        target_val = self.target_model.predict(next_states)\n",
        "\n",
        "        # 벨만 최적 방정식을 이용한 업데이트 타깃\n",
        "        for i in range(self.batch_size):\n",
        "            if dones[i]:\n",
        "                target[i][actions[i]] = rewards[i]\n",
        "            else:\n",
        "                target[i][actions[i]] = rewards[i] + self.discount_factor * (\n",
        "                    np.amax(target_val[i]))\n",
        "\n",
        "        self.model.fit(states, target, batch_size=self.batch_size,\n",
        "                       epochs=1, verbose=0)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUw6blLiSHTg",
        "outputId": "bb243c96-d2d0-4afa-e1bb-9a351031f3fa"
      },
      "source": [
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "\n",
        "display = Display(visible=False, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.7/dist-packages (from piglet) (1.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (3.0.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (21.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (2.0.1)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.37.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f832a9d0410>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "uja7OUQxFCx6",
        "outputId": "95766576-296c-4bb3-f30b-58b26c43bebe"
      },
      "source": [
        "#EPISODES = 300\n",
        "EPISODES = 3\n",
        "\n",
        "# CartPole-v1 환경, 최대 타임스텝 수가 500\n",
        "env = gym.make('LunarLander-v2')\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "# DQN 에이전트 생성\n",
        "agent = DQNAgent(state_size, action_size)\n",
        "\n",
        "scores, episodes = [], []\n",
        "\n",
        "done_cnt = 0\n",
        "\n",
        "for e in range(EPISODES+1):\n",
        "    done = False\n",
        "    score = 0\n",
        "    cnt = 0\n",
        "    # env 초기화\n",
        "    state = env.reset() #== obs\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    img = env.render(mode='rgb_array')\n",
        "    n_images = 100\n",
        "    images = []\n",
        "\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      if agent.render:\n",
        "        env.render()\n",
        "\n",
        "\n",
        "      # 현재 상태로 행동을 선택\n",
        "      action = agent.get_action(state)\n",
        "      # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
        "      next_state, reward, done, position = env.step(action)\n",
        "      next_state = np.reshape(next_state, [1, state_size])\n",
        "      # 에피소드가 중간에 끝나면 -100 보상\n",
        "      reward = reward if not done or score == 499 else -100\n",
        "\n",
        "      img = env.render(mode='rgb_array')\n",
        "\n",
        "      #print(f'no edit reward : {reward}')\n",
        "      # 리플레이 메모리에 샘플 <s, a, r, s'> 저장\n",
        "      agent.append_sample(state, action, reward, next_state, done)\n",
        "      # 매 타임스텝마다 학습\n",
        "      if len(agent.memory) >= agent.train_start:\n",
        "          agent.train_model()\n",
        "\n",
        "      score += reward\n",
        "      state = next_state\n",
        "      #print(f'score : {score}, reward : {reward}')\n",
        "      if done:\n",
        "          reward += 10\n",
        "\n",
        "          # 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트\n",
        "          agent.update_target_model()\n",
        "\n",
        "          score = score if score == 500 else score + 100\n",
        "          # 에피소드마다 학습 결과 출력\n",
        "          scores.append(score)\n",
        "          episodes.append(e)\n",
        "          print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
        "\n",
        "          # 이전 10개 에피소드의 점수 평균이 490보다 크면 학습 중단\n",
        "          if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
        "              agent.model.save_weights(\"./lunar_lander_v2.h5\")\n",
        "              sys.exit()\n",
        "    imageio.mimwrite('./lander.gif',[np.array(img) for i, img in enumerate(images) if i%2 == 0],fps=29)\n",
        "\n",
        "    if e % 100 == 0:\n",
        "      agent.model.save_weights(\"./lunar_lander_v2.h5\")\n",
        "      pylab.plot(episodes, scores, 'b')\n",
        "      pylab.savefig(\"./lunar_lander_v2.png\")\n",
        "\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,324\n",
            "Trainable params: 1,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,324\n",
            "Trainable params: 1,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0   score: -7.730431052963894   memory length: 63   epsilon: 0.9426789411643326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f832a4710d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1   score: -60.218357816638445   memory length: 100   epsilon: 0.8658253647948594\n",
            "episode: 2   score: -308.8812691665953   memory length: 100   epsilon: 0.7609888362515699\n",
            "episode: 3   score: -247.36121587235766   memory length: 100   epsilon: 0.6954601118039707\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQRUlEQVR4nO3df6xfdX3H8edLGn+Ag4IUsWJX3B9sarI6vmFq1onQ+YM5McwUSHTgho2Z2YTFbJgumz8WN1EyXZZsaSCLyzZkgkanDKRubPqHuFusE6WsCKhttVyHdIpBhr73xz3NLuX7vb/Oub2tn+cjObnnnM/7ez6fDzd53S+f8/32pKqQJP3ke9JKD0CSdHgY+JLUCANfkhph4EtSIwx8SWrEqpUewFxOPvnkWr9+/UoPQ5KOGjt27PhOVa0Z13ZEB/769euZmppa6WFI0lEjydcntbmkI0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDWi1zNtk1wPnNEdrgYeqqoNE2qPAaaAvVX16j79SpIWr1fgV9WFB/eTXA0cmKP8rcBdwPF9+pQkLc0gSzpJAmwGrpvQfhrwq8A1Q/QnSVq8odbwNwL7q2r3hPYPAL8P/Hig/iRJizTvkk6S7cCpY5q2VtXHu/2Lmfzu/tXAA1W1I8nZC+hvC7AFYN26dfOVS5IWKFXV7wLJKmAvcGZV7RnT/qfAG4DHgKcys4b/0ap6/XzXHo1GNTU11Wt8ktSSJDuqajSubYglnU3ArnFhD1BVb6+q06pqPXAR8C8LCXtJ0rCGCPyLOGQ5J8naJDcNcG1J0kB6fSwToKouHXNuH3DemPO3Abf17VOStHh+01aSGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5Ia0euJV0muB87oDlcDD1XVhjF19wPfA34EPDbpAbuSpOXTK/Cr6sKD+0muBg7MUf6yqvpOn/4kSUvX+5m2AEkCbAbOGeJ6kqThDbWGvxHYX1W7J7QX8OkkO5JsmetCSbYkmUoyNT09PdDwJEnzvsNPsh04dUzT1qr6eLd/MXDdHJf5param+QU4NYku6rq38cVVtU2YBvAaDSq+cYnSVqYeQO/qjbN1Z5kFXABcOYc19jb/XwgyceAs4CxgS9JWh5DLOlsAnZV1Z5xjUmOS/JTB/eBlwN3DtCvJGkRhgj8izhkOSfJ2iQ3dYfPBD6X5EvAF4BPVdXNA/QrSVqE3p/SqapLx5zbB5zX7d8L/HzffiRJ/fhNW0lqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWpEr8BPcn2Snd12f5KdE+pWJ7khya4kdyV5cZ9+JUmL1+sRh1V14cH9JFcDByaUfhC4uapel+TJwLF9+pUkLV7vZ9oCJAmwGThnTNsJwC8DlwJU1aPAo0P0K0lauKHW8DcC+6tq95i204Fp4G+SfDHJNUmOm3ShJFuSTCWZmp6eHmh4kqR5Az/J9iR3jtnOn1V2MXDdhEusAn4B+KuqeiHwMHDlpP6qaltVjapqtGbNmkVMRZI0l3mXdKpq01ztSVYBFwBnTijZA+ypqtu74xuYI/AlSctjiCWdTcCuqtozrrGqvg18M8kZ3alzga8O0K8kaRGGCPyLOGQ5J8naJDfNOvU7wN8n+U9gA/CeAfqVJC1C70/pVNWlY87tA86bdbwTGPXtS5K0dH7TVpIaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUiF6Bn+T6JDu77f4kO8fUnDGrZmeS/0lyeZ9+JUmL1+uJV1V14cH9JFcDB8bU3M3MYw1JcgywF/hYn34lSYvX+xGHAEkCbAbOmaf0XOBrVfX1IfqVJC3cUGv4G4H9VbV7nronPPD8UEm2JJlKMjU9PT3Q8CRJ8wZ+ku1J7hyznT+r7GLmD/InA68BPjJXXVVtq6pRVY3WrFmzkDlIkhZg3iWdqto0V3uSVcAFwJnzXOpVwB1VtX/hw5MkDWWIJZ1NwK6q2jNP3bz/FyBJWj5DBP4T1uWTrE1y06zj44BfAT46QH+SpCXo/Smdqrp0zLl9wHmzjh8GntG3L0nS0vlNW0lqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWpErydeJbkeOKM7XA08VFUbxtRdAVwGFPBl4I1V9UifviVJi9PrHX5VXVhVG7qQv5Exz6xN8mzgd4FRVb0AOIaZ5+BKkg6j3s+0BUgSYDNwzhz9PC3J/wLHAvuG6FeStHBDreFvBPZX1e5DG6pqL/B+4BvAt4ADVfXpSRdKsiXJVJKp6enpgYYnSZo38JNsT3LnmO38WWUXA9dNeP2JwPnA6cBa4Lgkr5/UX1Vtq6pRVY3WrFmzuNlIkiaad0mnqjbN1Z5kFXABcOaEkk3AfVU13dV/FHgJ8HeLG6okqY8hlnQ2Abuqas+E9m8AL0pybLfWfy5w1wD9SpIWYYjAv4hDlnOSrE1yE0BV3Q7cANzBzEcynwRsG6BfSdIipKpWegwTjUajmpqaWulhSNJRI8mOqhqNa/ObtpLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRvQK/CTXJ9nZbfcn2Tmh7q3dg8+/kuTyPn1KkpZm3oeYz6WqLjy4n+Rq4MChNUleALwJOAt4FLg5ySer6p4+fUuSFmeQJZ3u4eSbOeTZtp2fA26vqh9U1WPAvwEXDNGvJGnhhlrD3wjsr6rdY9ruBDYmeUaSY4HzgOdMulCSLUmmkkxNT08PNDxJ0rxLOkm2A6eOadpaVR/v9i9m/Lt7ququJO8FPg08DOwEfjSpv6raBmyDmYeYzzc+SdLCzBv4VbVprvYkq5hZojlzjmtcC1zb1b8H2LO4YUqS+up107azCdhVVRNDPMkpVfVAknXM/HF40QD9SpIWYYg1/Is4ZDknydokN806dWOSrwL/BLylqh4aoF9J0iL0fodfVZeOObePmZuzB4839u1HktSP37SVpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRvQO/CQbknw+yc4kU0nOmlB3SZLd3XZJ334lSYszxEPMrwLeWVX/nOS87vjs2QVJTgL+GBgBBexI8omq+u4A/UuSFmCIJZ0Cju/2TwD2jal5BXBrVT3YhfytwCsH6FuStEBDvMO/HLglyfuZ+QPykjE1zwa+Oet4T3fuCZJsAbYArFu3boDhSZJggYGfZDtw6pimrcC5wBVVdWOSzcC1wKalDqiqtgHbAEajUS31OpKkx1tQ4FfVxABP8rfAW7vDjwDXjCnby+PX9U8DblvQCCVJgxhiDX8f8NJu/xxg95iaW4CXJzkxyYnAy7tzkqTDZIg1/DcBH0yyCniEbv09yQh4c1VdVlUPJnk38B/da95VVQ8O0LckaYFSdeQuk49Go5qamlrpYUjSUSPJjqoajWvzm7aS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEb0CvwkG5J8PsnOJFNJzppQd3OSh5J8sk9/kqSl6/sO/yrgnVW1Afij7nic9wFv6NmXJKmHvoFfwPHd/gnMPND8iUVVnwG+17MvSVIPfR9ifjlwS5L3M/PH4yX9hyRJWg7zBn6S7cCpY5q2AucCV1TVjUk2A9cCm/oMKMkWYAvAunXr+lxKkjRLqmrpL04OAKurqpIEOFBVx0+oPRt4W1W9eqHXH41GNTU1teTxSVJrkuyoqtG4tr5r+PuAl3b75wC7e15PkrRM+q7hvwn4YJJVwCN0SzFJRsCbq+qy7vizwM8CT0+yB/itqrqlZ9+SpEXoFfhV9TngzDHnp4DLZh1v7NOPJKk/v2krSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mN6PWPpy23JNPA11d6HIt0MvCdlR7EYeac2+Ccjw4/XVVrxjUc0YF/NEoyNelfqvtJ5Zzb4JyPfi7pSFIjDHxJaoSBP7xtKz2AFeCc2+Ccj3Ku4UtSI3yHL0mNMPAlqREG/hIkOSnJrUl2dz9PnFB3SVezO8klY9o/keTO5R9xf33mnOTYJJ9KsivJV5L82eEd/eIkeWWSu5Pck+TKMe1PSXJ91357kvWz2t7enb87ySsO57iXaqnzTfIrSXYk+XL385zDPfal6vM77trXJfl+krcdrjEPoqrcFrkBVwFXdvtXAu8dU3MScG/388Ru/8RZ7RcA/wDcudLzWe45A8cCL+tqngx8FnjVSs9pwjyPAb4GPLcb65eA5x1S89vAX3f7FwHXd/vP6+qfApzeXeeYlZ7TMs73hcDabv8FwN6Vns9yz3lW+w3AR4C3rfR8FrP5Dn9pzgc+1O1/CHjtmJpXALdW1YNV9V3gVuCVAEmeDvwe8CeHYaxDWfKcq+oHVfWvAFX1KHAHcNphGPNSnAXcU1X3dmP9MDNzn232f4sbgHOTpDv/4ar6YVXdB9zTXe9ItuT5VtUXq2pfd/4rwNOSPOWwjLqfPr9jkrwWuI+ZOR9VDPyleWZVfavb/zbwzDE1zwa+Oet4T3cO4N3A1cAPlm2Ew+s7ZwCSrAZ+DfjMcgxyAPPOYXZNVT0GHACescDXHmn6zHe2XwfuqKofLtM4h7TkOXdv1v4AeOdhGOfgVq30AI5USbYDp45p2jr7oKoqyYI/25pkA/AzVXXFoeuCK2255jzr+quA64C/qKp7lzZKHWmSPB94L/DylR7LYfAO4M+r6vvdG/6jioE/QVVtmtSWZH+SZ1XVt5I8C3hgTNle4OxZx6cBtwEvBkZJ7mfmv/8pSW6rqrNZYcs454O2Abur6gMDDHe57AWeM+v4tO7cuJo93R+xE4D/XuBrjzR95kuS04CPAb9RVV9b/uEOos+cfxF4XZKrgNXAj5M8UlV/ufzDHsBK30Q4GjfgfTz+BuZVY2pOYmad78Ruuw846ZCa9Rw9N217zZmZ+xU3Ak9a6bnMM89VzNxsPp3/v6H3/ENq3sLjb+j9Y7f/fB5/0/Zejvybtn3mu7qrv2Cl53G45nxIzTs4ym7arvgAjsaNmfXLzwC7ge2zQm0EXDOr7jeZuXF3D/DGMdc5mgJ/yXNm5h1UAXcBO7vtspWe0xxzPQ/4L2Y+ybG1O/cu4DXd/lOZ+YTGPcAXgOfOeu3W7nV3c4R+Emmo+QJ/CDw863e6Ezhlpeez3L/jWdc46gLff1pBkhrhp3QkqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWrE/wHP1FzwRWJ6wgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jySAWFCJldb",
        "outputId": "dfb2b05c-33f6-4dd5-e9a7-bef0b17d79b0"
      },
      "source": [
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "\n",
        "display = Display(visible=False, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f66bdc3aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Gg3w0wPcGeaS",
        "outputId": "00353fc4-e79c-417e-be04-56cfbb062bfd"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "# Number of images to capture\n",
        "n_images = 1200\n",
        "\n",
        "images = []\n",
        "\n",
        "# init a new episode\n",
        "obs = env.reset()\n",
        "# init the img var with the starting state of the env\n",
        "img = env.render(mode='rgb_array')\n",
        "\n",
        "for i in range(n_images):\n",
        "  # At each step, append an image to list\n",
        "  images.append(img)\n",
        "\n",
        "  # Advance a step and render a new image\n",
        "  action, _ = predict(obs)\n",
        "  obs, _, _ ,_ = env.step(action)\n",
        "  img = env.render(mode='rgb_array')\n",
        "\n",
        "imageio.mimwrite('./lander.gif',\n",
        "                [np.array(img) for i, img in enumerate(images) if i%2 == 0],\n",
        "                fps=29)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-df3952d2f4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Advance a step and render a new image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ff8ds1kJX31"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}