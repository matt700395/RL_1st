{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lunarlander_dqn_ver_korea_1_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP51LIU3C7YBO4lGR4S6vtZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matt700395/RL_1st/blob/master/lunarlander_dqn_ver_korea_1_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TyPF_wxFgjl",
        "outputId": "ac523d16-b695-4666-95cc-db408a757383"
      },
      "source": [
        "!pip install stable-baselines==2.7.0\n",
        "!pip install box2d-py\n",
        "!pip install gym pyvirtualdisplay\n",
        "!apt install xvfb -y\n",
        "!pip install piglet\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "\n",
        "# Set up display; otherwise rendering will fail for\n",
        "# classic control type envs, apparently\n",
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "\n",
        "# See https://github.com/ipython/ipython/issues/10045#issuecomment-522697219\n",
        "#from IPython.core.interactiveshell import InteractiveShell\n",
        "#InteractiveShell.ast_node_interactivity = \"all\"\n",
        "#from IPython import display\n",
        "\n",
        "import sys\n",
        "import gym\n",
        "import pylab\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines==2.7.0 in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (0.17.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.1.5)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (3.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.7.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines==2.7.0) (2018.9)\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.7/dist-packages (from piglet) (1.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (21.2.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (2.0.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (3.0.6)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.37.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXKZVeUjFBqM"
      },
      "source": [
        "# 카트폴 예제에서의 DQN 에이전트\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.render = False\n",
        "\n",
        "        # 상태와 행동의 크기 정의\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # DQN 하이퍼파라미터\n",
        "        self.discount_factor = 0.99\n",
        "        self.learning_rate = 0.001\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.999\n",
        "        self.epsilon_min = 0.01\n",
        "        #self.batch_size = 32\n",
        "        #self.train_start = 1000\n",
        "        self.batch_size = 5\n",
        "        self.train_start = 5\n",
        "\n",
        "        # 리플레이 메모리, 최대 크기 2000\n",
        "        #self.memory = deque(maxlen=20000)\n",
        "        self.memory = deque(maxlen=100)\n",
        "\n",
        "        # 모델과 타깃 모델 생성\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "\n",
        "        # 타깃 모델 초기화\n",
        "        self.update_target_model()\n",
        "\n",
        "\n",
        "    # 상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(30, input_dim=self.state_size, activation='relu',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.add(Dense(30, activation='relu',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.add(Dense(self.action_size, activation='linear',\n",
        "                        kernel_initializer='he_uniform'))\n",
        "        model.summary()\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    # 타깃 모델을 모델의 가중치로 업데이트\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    # 입실론 탐욕 정책으로 행동 선택\n",
        "    def get_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        else:\n",
        "            q_value = self.model.predict(state)\n",
        "            return np.argmax(q_value[0])\n",
        "\n",
        "    # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장\n",
        "    def append_sample(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "    def train_model(self):\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "        # 메모리에서 배치 크기만큼 무작위로 샘플 추출\n",
        "        mini_batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states = np.zeros((self.batch_size, self.state_size))\n",
        "        next_states = np.zeros((self.batch_size, self.state_size))\n",
        "        actions, rewards, dones = [], [], []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            states[i] = mini_batch[i][0]\n",
        "            actions.append(mini_batch[i][1])\n",
        "            rewards.append(mini_batch[i][2])\n",
        "            next_states[i] = mini_batch[i][3]\n",
        "            dones.append(mini_batch[i][4])\n",
        "\n",
        "        # 현재 상태에 대한 모델의 큐함수\n",
        "        # 다음 상태에 대한 타깃 모델의 큐함수\n",
        "        target = self.model.predict(states)\n",
        "        target_val = self.target_model.predict(next_states)\n",
        "\n",
        "        # 벨만 최적 방정식을 이용한 업데이트 타깃\n",
        "        for i in range(self.batch_size):\n",
        "            if dones[i]:\n",
        "                target[i][actions[i]] = rewards[i]\n",
        "            else:\n",
        "                target[i][actions[i]] = rewards[i] + self.discount_factor * (\n",
        "                    np.amax(target_val[i]))\n",
        "\n",
        "        self.model.fit(states, target, batch_size=self.batch_size,\n",
        "                       epochs=1, verbose=0)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUw6blLiSHTg",
        "outputId": "b984359c-af97-4b86-d366-062d84056f04"
      },
      "source": [
        "display = Display(visible=False, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f831c07b7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "uja7OUQxFCx6",
        "outputId": "af9c40d1-1d0e-401a-ac88-e7500ca1ad43"
      },
      "source": [
        "#EPISODES = 300\n",
        "EPISODES = 1\n",
        "\n",
        "# CartPole-v1 환경, 최대 타임스텝 수가 500\n",
        "env = gym.make('LunarLander-v2')\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "# DQN 에이전트 생성\n",
        "agent = DQNAgent(state_size, action_size)\n",
        "\n",
        "scores, episodes = [], []\n",
        "\n",
        "done_cnt = 0\n",
        "\n",
        "for e in range(EPISODES+1):\n",
        "    done = False\n",
        "    score = 0\n",
        "    cnt = 0\n",
        "    # env 초기화\n",
        "    state = env.reset() #== obs\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "\n",
        "    #gif 저장관련1\n",
        "    img = env.render(mode='rgb_array')\n",
        "    n_images = 100\n",
        "    images = []\n",
        "\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      if agent.render:\n",
        "        env.render()\n",
        "\n",
        "\n",
        "      # 현재 상태로 행동을 선택\n",
        "      action = agent.get_action(state)\n",
        "      # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
        "      next_state, reward, done, position = env.step(action)\n",
        "      next_state = np.reshape(next_state, [1, state_size])\n",
        "      # 에피소드가 중간에 끝나면 -100 보상\n",
        "      reward = reward if not done or score == 499 else -100\n",
        "\n",
        "      #gif 저장관련2\n",
        "      img = env.render(mode='rgb_array')\n",
        "\n",
        "      # 리플레이 메모리에 샘플 <s, a, r, s'> 저장\n",
        "      agent.append_sample(state, action, reward, next_state, done)\n",
        "      # 매 타임스텝마다 학습\n",
        "      if len(agent.memory) >= agent.train_start:\n",
        "          agent.train_model()\n",
        "\n",
        "      score += reward\n",
        "      state = next_state\n",
        "      #print(f'score : {score}, reward : {reward}')\n",
        "      if done:\n",
        "          reward += 10\n",
        "\n",
        "          # 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트\n",
        "          agent.update_target_model()\n",
        "\n",
        "          score = score if score == 500 else score + 100\n",
        "          # 에피소드마다 학습 결과 출력\n",
        "          scores.append(score)\n",
        "          episodes.append(e)\n",
        "          print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
        "\n",
        "          # 이전 10개 에피소드의 점수 평균이 490보다 크면 학습 중단\n",
        "          if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
        "              agent.model.save_weights(\"./lunar_lander_v2.h5\")\n",
        "              sys.exit()\n",
        "\n",
        "    #gif 저장관련3\n",
        "    imageio.mimwrite('./lander.gif',[np.array(img) for i, img in enumerate(images) if i%2 == 0],fps=29)\n",
        "\n",
        "    if e % 100 == 0:\n",
        "      agent.model.save_weights(\"./lunar_lander_v2.h5\")\n",
        "      pylab.plot(episodes, scores, 'b')\n",
        "      pylab.savefig(\"./lunar_lander_v2.png\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,324\n",
            "Trainable params: 1,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_39 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 4)                 124       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,324\n",
            "Trainable params: 1,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0   score: -24.860567644636504   memory length: 66   epsilon: 0.9398537314349842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8329bffed0>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1   score: -0.20154916479137341   memory length: 100   epsilon: 0.8666920568517111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jySAWFCJldb",
        "outputId": "dfb2b05c-33f6-4dd5-e9a7-bef0b17d79b0"
      },
      "source": [
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gym\n",
        "\n",
        "display = Display(visible=False, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f66bdc3aa10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Gg3w0wPcGeaS",
        "outputId": "00353fc4-e79c-417e-be04-56cfbb062bfd"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "# Number of images to capture\n",
        "n_images = 1200\n",
        "\n",
        "images = []\n",
        "\n",
        "# init a new episode\n",
        "obs = env.reset()\n",
        "# init the img var with the starting state of the env\n",
        "img = env.render(mode='rgb_array')\n",
        "\n",
        "for i in range(n_images):\n",
        "  # At each step, append an image to list\n",
        "  images.append(img)\n",
        "\n",
        "  # Advance a step and render a new image\n",
        "  action, _ = predict(obs)\n",
        "  obs, _, _ ,_ = env.step(action)\n",
        "  img = env.render(mode='rgb_array')\n",
        "\n",
        "imageio.mimwrite('./lander.gif',\n",
        "                [np.array(img) for i, img in enumerate(images) if i%2 == 0],\n",
        "                fps=29)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-df3952d2f4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Advance a step and render a new image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ff8ds1kJX31"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}